# Lab Report: Corpus Analysis

#### ADRIANA MESSINA

## Process Description

During this lab, we worked with a farily large set of data: 150 of longest science fiction books in the Gutenberg project collection. By using computational methods, we were able to look at larger trends across a lot of items and a lot of data.

We utilized the Gutenberg data to create a sentiment analysis. We used a sentiment dictionary algorithm to assign each word a numerical value from most negative to most positive emotional valence. Words are assigned to different emotional categories, such as disgust, joy, or trust. Our specific algorithm classified the appearance of each word with a certain sentiment and got rid of stop words. In our case, we filtered based on the sentiment anger to see what anger words came up most often across the entire corpus (force, death, gun). We also sorted the books by which ones contain the most angry words and created a ratio of angry words to other words to list proportion of angry words to total text length (EmoRatio). We then redid this process with a  different sentiment - I chose disgust and used the same algorithm to find the books that use the most disgust words.

Then we began topic modeling. Latent dirichlet allocation (LDA) organizes collections of documents into topics. Words that often appear next to each other are sorted into the same topics. The algorithm then cycles through many times, looking for words that appear together to create a probability analysis that words belong together. LDA typically works best with smaller chunks of corpus where there might be more semantic meaning, so we divided up our Gutenberg scifi books into chunks. finally, we created a document term matrix (DTM). This listed every document on one axis and every word on the other, filling in the intersections with the count of each term in each document and giving us a way to calculate how likely it is that words will appear together. We took turns running the LDA code, choosing what we want to explore and discussing our findings across the corpus.


## Observations

Something I thought was really interesting throughout this lab was the human side of data analysis. Sentiment analysis specifically raised some questions in my mind: why do certain words belong in their given sentiment category? How are dictionaries constructed and what assumptions do they make? While creating our sentiment analysis, we discussed the debate surrounding which algorithm best reflects actual language. Clearly, a hot topic of data management and analysis is the path to creating more impartial code that avoids making too many assumptions. The codes that process large amounts of data are made by humans, so they all inherently have biases. These biases in the data will ultimately determine the results at some level, so it is crucial to not impose our preconceived notions into our datat analysis. 

During the lab, I also thought a lot about how new technologies are changing the idea of the textual object. This is something we've talked about a lot in class, but was hard for me to grasp until I got to be hands-on in this lab. As an emglish minor, I inherently think of text as meant for being read, understood, and reflected upon. It creates emotions, raises questions, and hopefully provides some new knowledge for its readers. In this lab, however, text was data that could be analyzed, put into an algorithm, organized, and graphed. It created access to new kinds of information that I hadn't considered as part of the text before, such as trends across a corpus. Digitized text can become very abstract, but it can still provide us with knowledge, just in a different way.

## Analysis

D'Ignazio and Klein's "What Gets Counted Counts" was really interesting to consider in the conext of this lab. Many algoriths cannot consider or count nonbinary, trans, or gender-nonconofrming people. However, this is at no fault of the algorithm itself but how it was designed. As I discussed in my observation, human biases leak into the way we structure code and the ways we analyze data. When we started our sentiment analysis, we began by just looking at the "angry" words per book. However, it took us all a moment to realize that these results weren't quite what they seemed. We had neglected to take into account book length, which we remedied by creating ratios in the next step of the lab. This showed me how easy it can be for people to misinterpret or ignore data even when it might reveal new or important information.

Similarly, in Cordell and Mullen's "Fugitive Verses" data that may have been lost or ignored is noticed, and reveals new information. Nineteenth-century newspaper poems reveal a lot about the culture in the US at the time, specifically about how people "gleaned" newspapers and interacted with their favorite pieces. Without an algorithm, no one ever would've gone looking through old newspapers to discover these trends. The same concept applies within our lab. None of us would've ever gone looking through ever scifi book in the Gutenberg collection by hand, at least not with much success. Coding made a monumental task manageable and created useful information that we could use to discover and analyze trends.

Data anlysis is something that I really didn't expect to like, but putting it in context with these readings opened me up to the possibilitis coding could have. Especially in our increasingly online and interconnected world, processing tons of data all at once is an important challenge to overcome.It's easy to see this process as the unfeeling work of a computer, but humans have a bigger hand in these problems than I realized. Coding is not just for ad targeting; it can be used for the benefit of social justice, equality, and learning.

P.S. Thank you for the Thanksgiving invitations Prof. Cordell. I am grateful to have the means to go home to for the holidays, and I am equally grateful that you are there for those who don't.